{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습정리\n",
    "\n",
    "### 26장. 데이터 윤리\n",
    "        \n",
    "####  26.1 데이터 윤리란 무엇인가?\n",
    "* 데이터 윤리(data ethics)\n",
    "    * 데이터의 오용 \n",
    "        * 정치적 광고 타겟팅에 사용\n",
    "        * 자율 주행 자동차 사고 발생\n",
    "        * 범죄자들의 재범율 예측 알고리즘에 따른 형량 부과\n",
    "    \n",
    "####  26.2 아니, 진짜로, 데이터 윤리가 뭔데?\n",
    "* 윤리(ethics) : 옳고 그른 행동을 판단하기 위한 틀 \n",
    "* 데이터 윤리 : 데이터 관련된 행동의 옳고 그름을 판단하기 위한 틀\n",
    "    * 의견의 불일치가 생기기 때문에 어떠한 행동의 윤리적 결과를 항상 고민하는 것이 중요\n",
    "\n",
    "####  26.3 데이터 윤리에 대해 신경 써야 할까?\n",
    "* 어떤 일을 하든 윤리에 대해 신경을 써야 한다.\n",
    "* 기술적 문제에 대해 개인이 내린 결정이 광범위한 효과를 낼 여지가 있음\n",
    "    * 업무의 영향력이 클수록 이런 부분을 더욱 많이 고민해야 한다.\n",
    "    * 본인 스스로가 결정 \n",
    "   \n",
    "####  26.4 나쁜 데이터 제품 만들기\n",
    "* 나쁜 제품을 만들어서 생긴 데이터 윤리 이슈\n",
    "    * 마이크로 소프트의 챗봇 - 테이\n",
    "        * 트윗을 흉내내는 챗봇, 인종차별 요소로 오용되는 경우가 생김\n",
    "    * 구글 포토 \n",
    "        * 흑인을 고릴라로 분류하는 이미지 인식 알고리즘을 사용했던 경우 \n",
    "        * 나쁜 학습 데이터, 모델 부정확도등이 요인 \n",
    "    \n",
    "####  26.5 정확도와 공정함의 균형을 유지\n",
    "* ex. 사람들이 특정 행동을 할 것인지 예측하는 모델에 관한 논쟁\n",
    "    * 그룹별로 다르게 예측을 하는 경우 : 두 그룹을 불공정하게 대하고 있다는 논쟁 \n",
    "    * 그룹별로 다른 결과를 예측한 경우 : 결과가 한 그룹을 낙인을 찍는다는 논쟁\n",
    "    * 예측이 그룹과 무관하게 같은 경우 : 정확도에 관한 논쟁\n",
    "    \n",
    "* 정확도와 공정함 사이에 trade-off관계가 있을 수 있고, 올바른 해답이 항상 존재하지는 않을 수 있다.     \n",
    "\n",
    "####  26.6 협력\n",
    "* 주제가 제한되고 감시되는 서비스를 제공하는 것이 나을까, 제공하지 않는 것이 나을까?\n",
    "\n",
    "####  26.7 해석 가능성\n",
    "* ex. 퇴사할 가능성이 가장 높은 임직원을 예측하는 모델 개발\n",
    "    * 고려 모델\n",
    "        * 의사결정나무\n",
    "        * 인공신경망\n",
    "            * 예측에 대한 해석이 불가능, 해석이 큰 변화를 일으키는데 도움이 되므로 사용 반대의 입장.\n",
    "        * 값비싼 '임직원 유지 전문가'\n",
    "            * 전문가가 설명을 제시할 수는 있더라도, 그 사람의 설명이 진짜 예측된 결과의 이유인지는 보장할 수 없다.\n",
    "    * 성능이 비록 나쁘더라도 결과를 해석할 수 있는 모델을 선택할지, 가장 성능이 좋지만 결과 해석이 불가능한 모델을 선택할지 고려해야 될 수도 있다.\n",
    "\n",
    "####  26.8 추천\n",
    "* 구글 - 불쾌하거나 폄하하는 내용, 종교적인 내용에 대해 추천을 하지 않으려고 노력\n",
    "    * 진실이 때론 불쾌할 수도 있다. 그것을 제한하는 것은 윤리적인 것일까 비윤리 적인 것일까?\n",
    "    \n",
    "####  26.9 편향된 데이터\n",
    "* ex. 단어벡터 : 분포적 유사도를 유지하도록 만들어 짐\n",
    "    * 비슷한 맥락에서 등장하는 단어들은 비슷한 벡터로 표현됨\n",
    "    * 이는 학습 데이터 안의 편향이 단어 벡터에도 반영된다는 것을 의미\n",
    "    * ex. 구글 뉴스기사, 위키백과, 책..등에서 분포적 패턴을 학습하게 됨\n",
    "        * '소프트웨어' - '남성'과 더 가깝게 위치할 수 있다. \n",
    "        * 모델이 대표성이 없는 데이터를 사용한다면 실제 성능이 안좋을 가능성이 매우 높음\n",
    "            * 불쾌하거나 난처한 방식으로 동작할 수도 있다.\n",
    "    * 만약 현실의 데이터가 편향적인 영향의 결과라면 모델이 그러한 편향을 지속시킬 수도 있음\n",
    "        \n",
    "####  26.10 데이터 보호\n",
    "* 사용자에 대한 데이터를 활용하는데 있어서 여러가지 논쟁이 발생할 수 있다. \n",
    "\n",
    "####  26.11 요약\n",
    "* 현재 까지 수많은 문제들이 있으며 미래에도 수많은 문제가 발생할 수 있다.\n",
    "\n",
    "####  26.12 더 공부해 보고 싶다면\n",
    "* 트위터나 뉴스 사이트에서 관련 논란을 찾아보기\n",
    "* Ethics and Data Science-마이크 루이즈,힐러리 메이슨,DJ파틸 e북에서 데이터 윤리를 실제로 적용하는 내용을 다룬다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
