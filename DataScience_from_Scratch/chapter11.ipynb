{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습정리\n",
    "\n",
    "### 11장. 기계학습\n",
    "* 데이터 과학의 핵심 : 데이터 수집, 이해, 전처리, 형식을 바꾸는 것 \n",
    "\n",
    "#### 11.1 모델링\n",
    "* 모델(model) : 다양한 변수 간의 수학적(혹은 확률적)관계를 표현한 것\n",
    "    * model example\n",
    "        * 비즈니스 모델 : 간단한 수학적인 관계에 기반\n",
    "        * 요리책 모델 : 시행착오를 기반, 다양한 재료의 조합으로 가장 마음에 드는 조합을 찾을 때까지 요리\n",
    "        * 포커 모델 : 확률적 이론, 포커 규칙, 카드가 분배되는 불규칙한 과정에 대한 적절한 가정을 기반\n",
    "\n",
    "#### 11.2 기계학습이란?\n",
    "* 기계학습(machine learning) : 데이터를 통해 모델을 만들고 사용하는 것\n",
    "    * 예측 모델링(predictive modeling) / 데이터 마이닝(data mining)과 유사\n",
    "    * 주어진 데이터로 모델 구축, 새로운 데이터에 만들어진 모델을 적용해서 다양한 것을 예측\n",
    "        * ex. 이메일 스팸 예측 / 신용카드 사기 예측 / 쇼핑고객 광고 클릭 확률 예측 / 슈퍼볼 우승팀 예측\n",
    "    * 일반적으로 파라미터가 있는 파라메트릭(parametric)모델을 고른 후 데이터를 통해 파라미터 최적값을 찾음\n",
    "        * ex. 선형함수(키-몸무게), 의사결정나무(환자-병) \n",
    "        \n",
    "* 기계학습의 종류\n",
    "    * 지도학습(supervised learning) : 학습에 사용될 데이터에 정답이 포함되어 있는 학습\n",
    "    * 비지도 학습(unsupervised learning) : 학습에 사용될 데이터에 정답이 포함되어 있지 않는 학습\n",
    "    * 준 지도 학습(semi-supervised learning) : 데이터 일부에만 정답이 포함되어 있는 학습\n",
    "    * 온라인 학습(online learning) : 새로 들어오는 데이터를 통해 모델을 끊임없이 조정하는 학습\n",
    "    * 강화 학습(reinforcement learning) : 연속된 예측 뒤 모델이 얼마나 잘 예측했는지 파악하는 학습\n",
    "\n",
    "#### 11.3 오버피팅과 언더피팅\n",
    "* 오버피팅(overfitting) : 만들어진 모델의 성능이 학습 데이터에서는 좋지만, 관측한 적 없는 새로운 데이터에서 좋지 않은 경우\n",
    "    * 원인 \n",
    "        * 데이터의 잡음(noise)까지 학습\n",
    "        * 원하는 결과를 예측해 주는 요소가 아닌 다른 요소가 학습\n",
    "    * 모델이 너무 복잡하면 오버피팅이 발생, 학습 데이터 이외의 데이터에서는 일반적으로 적용할 수 없다\n",
    "    * 평가 데이터에 대한 성능이 좋은 모델은 오버피팅 되지 않았다고 볼 수 있음\n",
    "        * 더 큰 데이터에는 존재하지 않을 패턴이 학습데이터와 평가 데이터에 공통적으로 존재하는 경우도 존재\n",
    "        * 모델이 속성 간의 관계보다 사용자를 분류하도록 학습될 수도 있음\n",
    "    * 여러 모델 중에서 하나의 모델을 선택할 때 \n",
    "        * 각각의 모델은 오버피팅 되지 않아도 평가데이터에서 성능이 제일 좋은 모델을 선택한다면 이는 평가 데이터를 일종의 두번째 학습 데이터로 사용하는 메타 학습의 문제가 발생\n",
    "    \n",
    "    * solution\n",
    "        * 주어진 데이터를 나눔 : 전체 데이터의 일부로 학습, 일부로 성능을 평가\n",
    "        * 입력 변수(x) 출력변수(y) : 학습 데이터(training data)나 평가 데이터(test set)에 쌍을 이뤄서 들어가야함\n",
    "        * 데이터를 세 종류로 나눠서 사용\n",
    "            * train data : 모델 생성\n",
    "            * validation set : 모델 선택\n",
    "            * test set : 모델 성능 평가 \n",
    "        \n",
    "    \n",
    "* 언더피팅(underfitting) : 모델의 성능이 학습 데이터에서도 좋지 않은 경우\n",
    "    * 해당 모델이 문제에 적합하지 않은 경우. 새로운 모델을 찾아야함\n",
    "\n",
    "#### 11.4 정확도 \n",
    "* 이진 분류 : 두 가지 결론 중 하나를 선택\n",
    "* 혼동행렬(confusion matrix) : $\\begin{vmatrix} & {real : spam} & {real : no spam}  \\\\ positive & TP & FP\\\\negative &FN& TN\\end{vmatrix}$\n",
    "        * TP(True positive) : 실제로도 스팸이 맞고, 스팸으로 분류도 옳게 함\n",
    "        * FP(False positive) : 실제로는 스팸이 아니고, 스팸으로 분류함\n",
    "        * FN(False negative) : 실제로는 스팸이 맞고, 스팸이 아니라고 분류함\n",
    "        * TN(True negative) : 실제로 스팸이 아니고, 스팸이 아니라고 맞게 분류함\n",
    "\n",
    "    * 혼동행렬을 사용해서 모델의 성능에 대한 다양한 지표를 계산 가능\n",
    "        * 정확도(accuracy) : 정확한 예측(True)의 비율 \n",
    "        * $accuracy = \\frac {TP + TN}{ALL}$\n",
    "        * 정밀도(precision) : positive로 예측된 결과의 정확도\n",
    "        * $precision = \\frac {TP}{TP+FP}$\n",
    "        * 재현율(recall) : 실제 positive중 정확하게 예측한 비율\n",
    "        * $recall = \\frac {TP}{TP+FN}$\n",
    "        * F1 점수(F1 score) : 정밀도와 재현율을 결합. 정밀도와 재현율의 조화평균\n",
    "        * $F1 score = \\frac {2 \\centerdot precision \\centerdot recall}{precision + recall}$\n",
    "    * 일반적으로 모델을 선택할 때 정밀도(precision)와 재현율(recall)의 trade-off를 고려해야함\n",
    "        * false positive와 false negative의 trade-off로 볼 수 있음\n",
    "        * trade-off 수준 결정 : 위험요소의 적당한 개수를 정하는 것\n",
    "        \n",
    "#### 11.5 Bias-variance 트레이드 오프\n",
    "* overfitting문제 : 편향(bias)과 분산(variance)의 trade-off\n",
    "    * underfitting : 편향이 크고 분산이 작음\n",
    "    * overfitting : 편향이 작고 분산이 큼\n",
    "\n",
    "* 편향이 클 때\n",
    "    * 새로운 변수를 추가\n",
    "* 분산이 너무 클 때\n",
    "    * 모델의 변수를 줄임\n",
    "    * 더 많은 데이터를 구해서 모델을 다시 학습\n",
    "\n",
    "#### 11.6 특성 추출 및 선택\n",
    "* 데이터의 특성을 나타내는 모델의 변수가 부족 : underfitting발생\n",
    "\n",
    "* 데이터의 특성(feature) : 모델의 모든 입력 변수\n",
    "    * boolean에 적합한 모델 : 나이브 베이즈 분류기, 회귀 분석\n",
    "    * continuous에 적합한 모델 : 회귀 분석 \n",
    "    * category에 적합한 모델 : 의사결정 나무\n",
    "\n",
    "* 데이터의 feature가 너무 많고 차원이 많을 때\n",
    "    * 차원 축소를 통해 입력 변수를 몇몇 중요한 변수로 축소, 더 적은 수의 변수로 데이터의 특성을 나타냄\n",
    "    * regularization : 변수의 개수가 늘어날수록 해당 모델을 불리하게 만드는 기법\n",
    "\n",
    "#### 11.7 더 공부해 보고 싶다면 \n",
    "* 코세라 : Machine Learning 강좌\n",
    "* The Elements of Statistical Learning : 수학적 교재 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
