{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 Learning rate and Evaluation\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu를 사용할때 device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed80a7bf7f24580ab8c7b3190a1e782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e0a0da0a0e407989ece387ce946f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2a8c611152458694513b6527cdff9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0131f4d521d542bf910c47401a7197bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkyuhun/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "# input 784, output 10 , bias True \n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax는 토치에서 내부적으로 계산함\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.534912467\n",
      "Epoch: 0002 cost = 0.359308660\n",
      "Epoch: 0003 cost = 0.331088185\n",
      "Epoch: 0004 cost = 0.316574216\n",
      "Epoch: 0005 cost = 0.307130307\n",
      "Epoch: 0006 cost = 0.300207913\n",
      "Epoch: 0007 cost = 0.294897258\n",
      "Epoch: 0008 cost = 0.290830433\n",
      "Epoch: 0009 cost = 0.287419558\n",
      "Epoch: 0010 cost = 0.284588993\n",
      "Epoch: 0011 cost = 0.281816244\n",
      "Epoch: 0012 cost = 0.279919624\n",
      "Epoch: 0013 cost = 0.277836829\n",
      "Epoch: 0014 cost = 0.276022315\n",
      "Epoch: 0015 cost = 0.274443209\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8867999911308289\n",
      "Label:  5\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict : 랜덤으로 하나를 잡고 예측 해보기 \n",
    "    r = random.randint(0, len(mnist_test) - 1) # 0~mnizst_test셋 중 하나의 인덱스 선택\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device) # 인덱스 하나 추출\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device) # 해당 예측값 라벨 추출 \n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
