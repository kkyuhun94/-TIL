{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN으로 MNIST 데이터 분석\n",
    "\n",
    "### 딥러닝 학습 단계 \n",
    "1. 라이브러리 호출\n",
    "2. GPU 사용호출\n",
    "3. 학습에 사용되는 parameter 설정\n",
    "4. 데이터 셋을 가져오고 loader 만들기 \n",
    "5. 학습 모델 만들기 (class CNN)\n",
    "6. Loss function (Criterion)을 선택, optimizer 선택\n",
    "7. train, loss check \n",
    "8. 성능 확인 \n",
    "\n",
    "### CNN 구조 \n",
    "\n",
    "* layer1\n",
    "    * `Convolution layer = (in_c=1,out_c=32, kernel_size=3, stride=1, padding =1)`\n",
    "    * `MaxPool layer = (kernel_size=2, stride=2)`\n",
    "* layer2 \n",
    "    * `Convolution layer = (in_c=32, out_c=64, kernel_size=3, stride=1, padding=1 )`\n",
    "    * `MaxPool layer = (kernel_size=2, stride=2)`\n",
    "\n",
    "* view => (batch_size x [7,7,64] => batch_size x[3136])\n",
    "* Fully_connect layer => (input=3136, output=10)\n",
    "\n",
    "### loss\n",
    "* Cross Entropy Loss\n",
    "    * SoftMax\n",
    "    * NLL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 11 MNIST and Convolutional Neural Network\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# CNN example\n",
    "inputs = torch.Tensor(1,1,28,28) # batch =1, channel=1, width,height=28\n",
    "print(inputs.shape)\n",
    "# maxpooling과 conv만 사용, relu는 예시에서는 생략\n",
    "con1 = nn.Conv2d(1,32,3,padding=1)\n",
    "pool = nn.MaxPool2d(2) # 반 x 반 \n",
    "con2 = nn.Conv2d(32,64,3,padding=1)\n",
    "print(con1)\n",
    "print(pool)\n",
    "print(con2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 64, 7, 7])\n",
      "torch.Size([1, 3136])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "out = con1(inputs)\n",
    "print(out.shape)\n",
    "out = pool(out)\n",
    "print(out.shape)\n",
    "out = con2(out)\n",
    "print(out.shape)\n",
    "out = pool(out)\n",
    "print(out.shape)\n",
    "out = out.view(out.size(0),-1)\n",
    "print(out.shape)\n",
    "fc = nn.Linear(3136,10)\n",
    "out = fc(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 사용\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    " \n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model (2 conv layers)\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # Final FC 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate CNN model\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "[Epoch:    1] cost = 0.220258787\n",
      "[Epoch:    2] cost = 0.0608599558\n",
      "[Epoch:    3] cost = 0.0459129922\n",
      "[Epoch:    4] cost = 0.0366976671\n",
      "[Epoch:    5] cost = 0.0299328379\n",
      "[Epoch:    6] cost = 0.0262569282\n",
      "[Epoch:    7] cost = 0.0208396725\n",
      "[Epoch:    8] cost = 0.0185660906\n",
      "[Epoch:    9] cost = 0.0157809369\n",
      "[Epoch:   10] cost = 0.013422614\n",
      "[Epoch:   11] cost = 0.0117681315\n",
      "[Epoch:   12] cost = 0.0086277714\n",
      "[Epoch:   13] cost = 0.00779873133\n",
      "[Epoch:   14] cost = 0.00714771263\n",
      "[Epoch:   15] cost = 0.00617111241\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train my model\n",
    "total_batch = len(data_loader)\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkyuhun/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/kkyuhun/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9854000210762024\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
