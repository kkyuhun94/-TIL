{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8. 딥러닝\n",
    "* 딥러닝 : 층을 깊게 한 심층 신경망\n",
    "\n",
    "#### 8.1 더 깊게 \n",
    "* 더 깊은 신경망으로 : 손글씨 숫자를 인식하는 심층 CNN\n",
    "    * 합성곱 계층(Conv) : 모두 3 x 3크기의 작은 필터, 층이 깊어지면서 채널수가 더 늘어남(채널수 : 16,16,32,32,64,64)\n",
    "    * 풀링 계층(Pool) : 중간 데이터의 공간 크기를 점차 줄여감\n",
    "    * 드롭아웃(Dropout) : 마지막 단 완전 연결 계층에서 드롭아웃 계층을 사용\n",
    "    * 활성화 함수 : ReLU, 초기값 : He초기값\n",
    "    * 가중치 매개병수 갱신 : Adam을 사용해 최적화\n",
    "* ![nn](deep_cnn.jpeg)\n",
    "\n",
    "* What is the class of this image? : 다양한 데이터셋을 대상으로 그동안 논문 등에서 발표한 기법들의 정확도 순위를 정리한 사이트\n",
    "    * 정확도를 더 높일 수 있는 기술이나 힌트를 발견할 수 있음\n",
    "        * 앙상블 학습\n",
    "        * 학습률 감소\n",
    "        * 데이터 확장 : 손쉽고 정확도 개선에 효과적\n",
    "\n",
    "* 데이터 확장(data augmentation) : 입력 이미지(훈련 이미지)를 알고리즘을 동원해 '인위적'으로 확장\n",
    "    * 입력 이미지를 회전하거나 세로로 이동, 미세한 변화를 주어 이미지의 개수를 늘림\n",
    "    * 데이터가 부족할 때 특히 효과적\n",
    "    * crop : 이미지 일부를 잘라냄\n",
    "    * flip : 이미지 좌우를 뒤집음\n",
    "    * 밝기 등의 외형 변화, 확대, 축소 등의 스케일 변화도 효과적\n",
    "\n",
    "* 층을 깊게 하는 이유 \n",
    "    * 이미지 인식 대회의 결과 : 상위권을 차지한 기법 대부분이 딥러닝 기반, 신경망을 더 깊게 만드는 방향으로 가고 있음\n",
    "    * 층을 깊게 할 때의 이점 : 신경망의 매개변수 수가 줄어듬 -> 넓은 수용 영역(receptive field)을 소화 가능\n",
    "        * 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같거나 이상의 표현력을 달성할 수 있음\n",
    "            * ex. 3 x 3의 합성곱 연산을 2회 수행으로 5 x 5의 합성곱 연산 1회를 대체 가능\n",
    "                * 3 x 3 연산 2회 : 매개변수(2x3x3=18)\n",
    "                * 5 x 5 연산 1회 : 매개변수(5x5=25)\n",
    "        * 수용영역 : 뉴런에 변화를 일으키는 국소적인 공간 영역\n",
    "        * 층을 거듭 할 수록 ReLU등의 활성화 함수를 계층사이에 배치함으로써 신경망의 표현력이 개선됨\n",
    "            * 활성화 함수가 신경망에 '비선형' 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문\n",
    "        * 학습의 효율성 : 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있음\n",
    "            * 층이 깊어 질 수록 단순한 것 보다 복잡한 것(텍스처, 사물의 일부)에 반응\n",
    "        * 신경망을 깊게 하면 학습할 문제를 계층적으로 분해할 수 있음\n",
    "            * 각 층이 학습해야 할 문제를 더 단순한 문제로 대체\n",
    "                * ex. 처음 층에서는 개가 등장하는 이미지보다 에지를 포함한 이미지가 많기 때문에 에지 학습을 먼저 실시\n",
    "            * 정보를 계층적으로 전달할 수 있음\n",
    "                * ex. 에지를 추출한 층의 다음 층은 에지 정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학습할 것으로 기대 \n",
    "                * \n",
    "                \n",
    "                \n",
    "                \n",
    "#### 8.2 딥러닝의 초기 역사\n",
    "* 이미지넷\n",
    "* VGG\n",
    "* GoogLeNet\n",
    "* ResNet\n",
    "\n",
    "#### 8.3 더 빠르게 (딥러닝 고속화)\n",
    "* 풀어야 할 숙제\n",
    "* GPU를 활용한 고속화 \n",
    "* 분산 학습\n",
    "* 연산 정밀도와 비트 줄이기 \n",
    "\n",
    "#### 8.4 딥러닝의 활용\n",
    "* 사물 검출\n",
    "* 분할\n",
    "* 사진 캡션 생성\n",
    "\n",
    "#### 8.5 딥러닝의 미래\n",
    "* 이미지 스타일(화풍) 변환\n",
    "* 이미지 생성\n",
    "* 자율 주행\n",
    "* Deep Q-Network(강화학습)\n",
    "\n",
    "#### 8.6 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
