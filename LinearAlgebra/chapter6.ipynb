{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Introduction to Linear Algebra\n",
    "> ### 📌선형대수학개론\n",
    "> 강좌를 들은 후 복습, 요약하면서 TIL에 기록\n",
    "    \n",
    "* [1. Linear Equations in Linear Algebra](https://github.com/kkyuhun94/TIL/blob/master/LinearAlgebra/1.LinearEquations_in_LinearAlgebra.md)\n",
    "* [2. Matrix Algebra]()\n",
    "* [3. Determinants]()\n",
    "* [4. Eigenvalues and Eigenvector]()\n",
    "* [5. Orthogonality and Least Squares]()\n",
    "* [6. Symmetric Matrices and Quadratic Forms]()\n",
    "* [7. Extra Algorithms]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    " \n",
    "### 6.Symmetric Matrices and Quardratic Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">6.1 Diagonalization of Symmetric Matrices\n",
    "\n",
    "* A symmetric matrix : $A^T=A$를 만족하는 square matrix\n",
    "\n",
    "* Diagonalization : $A$가 diagonal matrix $D$와 $similar$할때($A=PDP^{-1}$) \n",
    "\n",
    "* Theorem 1 :A가 symmetric일 때,\n",
    "    * 다른 eigenspace에 속한 eigenvector 들은 서로 orthogonal($v_1\\centerdot v_2$)\n",
    "\n",
    "* Orthogonally diagonalizable : $A$가 orthogonally diagonalizable하다.\n",
    "    * $\\leftrightarrow$ orthogonal matrix $P$가 존재, $A = PDP^T=PDP^{-1}$\n",
    "    * $\\leftrightarrow$ $A$ is symmetric($A=A^T$)\n",
    "\n",
    "* Orthogonally Diagonalizaion\n",
    "    * $A^T=A$ 확인\n",
    "    * eigenspaces, eigenvalues 계산\n",
    "    * orthogonal basis - Gram-Schmidt\n",
    "    * orthonomal basis by nomalization\n",
    "    * P,D 구함\n",
    "\n",
    "* The Spectral Theorem for Symmetric Matrix\n",
    "    * n x n symmetric matrix A의 성질\n",
    "        * a. 모든 eigenvalues가 real (multiplicity 허용)\n",
    "        * b. eigenspace의 dimension = $\\lambda$의 multiplicity \n",
    "        * c. 각자 다른 eigenvalue에 해당하는 eigenvector끼리는 orthogonal\n",
    "        * d. A는 orthogonally diagonalizable\n",
    "        \n",
    "*orthogonal matrix : orthonormal한 컬럼벡터들을 가진 square matrix\n",
    "\n",
    "* Spectral decomposition\n",
    "    * A는 orthogonally diagonalizable 할때\n",
    "        * $A=PDP^T$, $P$=[$u_1,u_2,...u_n$],$P$는 invertible,linearly independent, $D$는 diagonal \n",
    "        * $A=\\lambda_1u_1u_1^T+\\lambda_2u_2u_2^T+....+\\lambda_nu_nu_n^T$\n",
    " \n",
    "*spectrum=eigenvalues \n",
    "\n",
    ">6.2 Quardratic Forms\n",
    "\n",
    "* Quadratic Form\n",
    "    * $x\\centerdot x=x^Tx=x_1^2+x_2^2+...+x_n^2$\n",
    "    * x\\center x가 cross product를 갖고 있지 않으면 A는 diagonal.\n",
    "    * $Q(x)=x^TAx$을 만족하는 A는 n x n symmetric matrix.\n",
    "    * the matrix of quadratic form(Q)= quadratic matrix = A\n",
    "    * $x^TIx=\\lVert x \\rVert^2$\n",
    "\n",
    "* Change of variable in a Quadratic Form\n",
    "    * $x = Py \\to y=P^{-1}x$, $P$ = $[b_1,b_2,...b_n]$\n",
    "    * $x = y_1b_1+y_2b_2+...+y_nb_n$\n",
    "    * $x^TAx = y^TDy$, croos-product를 noncross-product로 만듬\n",
    "\n",
    "* Principal axes\n",
    "    * $A$는 n x n symmetric matrix일 때\n",
    "        * orthogonal change of variable, $x = Py$\n",
    "        * columns of $P$ : principal axes = orthonrmal basis of $R^n$\n",
    "    * $A$가 2 x 2일때 invertible symmetric matrix, $Q(x)=x^TAx=c$\n",
    "        * A가 diagonal : 타원,쌍곡선의 축\n",
    "        \n",
    "* Classifying quadratic forms\n",
    "    * $Q(x)=x^TAx$가 real-valued function\n",
    "        * positive dfinite : $Q(x) > 0$ , 0을제외한 모든x에 대해\n",
    "        * negative definite : $Q(x) < 0$, 0을제외한 모든x에 대해\n",
    "        * indefinite : Q(x)가 positive,negative 둘 다인 경우\n",
    "        * positive semidefinite : $Q(x) \\geq 0 $ , 모든 x에 대해 \n",
    "        * negative semidefinite : $Q(x) \\leq 0 $ , 모든 x에 대해\n",
    "    * $A$가 symmetric, qudratic form $x^TAx$ 일때\n",
    "        * a. positive definite : 모든 eigenvalue가 양수\n",
    "        * b. negative definite : 모든 eigenvalue가 음수\n",
    "        * c. indefinite : negative,positive 둘다 가지는 경우 \n",
    "  \n",
    ">6.3 Constrained Optimization\n",
    "\n",
    "* Constrained optimization\n",
    "    * $Q(x)=x^TAx$\n",
    "    * constraint(제약조건) : $x^Tx$\n",
    "\n",
    "* Theorem 6\n",
    "    * $A$가 symmetric할때, $m$ = min{$x^TAx:\\lVert x \\rVert = 1$},$M$ = max{$x^TAx:\\lVert x \\rVert = 1$}\n",
    "        * $\\lVert x \\rVert=1$ : 제약조건\n",
    "    * $A$의 가장 큰 eigenvalue $\\lambda _1$가 $M$,가장 작은 eigenvalue $\\lambda _2$가 $m$\n",
    "    * $x$가 $M$에 해당하는 unit eigenvector $u_1$일 때 $x^TAx$는 최대값 $M$을 가진다.\n",
    "    * $x$가 $m$에 해당하는 unit eigenvector $u_2$일 때 $x^TAx$는 최대값 $m$을 가진다.\n",
    "\n",
    "* Theorem 7\n",
    "    * Theorm6의 $A,\\lambda _1,and u_1$있고 constraints가 추가 될때:\n",
    "        * $x^Tx=1,x^Tu_1=0 $ : 제약추가($u_1$제외)\n",
    "    * $x$가 $\\lambda_2$에 해당하는 unit eigenvector $u_2$일때 두번째로 가장 큰 eigenvector, $\\lambda _2$가 최댓값 \n",
    "\n",
    "* Theorem 8\n",
    "    * $A$가 symmetric square matrix일 때 : orthogonal diagonalization $A = PDP^-1,$\n",
    "        * $D$는 크기순으로 $\\lambda_1\\geq\\lambda_2\\geq...\\geq\\lambda_n$ 정렬.\n",
    "        * P의 컬럼들은 unit eigenvectors $[u_1,..u_n]$\n",
    "    * k=2,...,n, the maximum value of x^TAx\n",
    "        * constraints : $x^Tx=1,x^Tu_1=0,...,x^Tu_{k-1}=0$일때,\n",
    "        * eigenvalue $\\lambda_k$ 최대값, x = u_k일때\n",
    " \n",
    ">6.4 The Singular Value Decomposition\n",
    "\n",
    "* SVD (The Singular Values of an m x n Matrix\n",
    "    * $A$가 임의의 $m$ x $n$ matrix\n",
    "    * $A^TA$는 symmetric matrix\n",
    "    * $A^TA$는 orthogonally diagonalizable\n",
    "    * {$v_1,...,v_n$}은 orthonormal basis for $R^n$, \n",
    "        * eigenvectors of $A^TA$ : $P =[v_1,...v_n]$\n",
    "    * $\\lambda _1,...\\lambda _n$는 eigenvalues of $A^TA$, nonnegative\n",
    "    * $\\lVert Av_i \\rVert^2 = \\lambda_i$\n",
    "    * $\\lambda_1 \\leq \\lambda_2 \\leq ...\\leq \\lambda_n \\leq 0$\n",
    "    * The singular values of $A$ : \n",
    "        * $\\lVert Av_i\\rVert$ = $\\sigma_i = \\sqrt {\\lambda_i}$\n",
    "    \n",
    "* Theorem 9\n",
    "    * {$v_1,...,v_n$} is orthonormal basis of $R^n$ : $A^TA$의 eigenvector\n",
    "    * $A^TA$의 eigenvalues는 크기 순으로 정렬 : $\\lambda_1 \\leq \\lambda_2 \\leq ...\\leq \\lambda_n$\n",
    "    * $r$ : $A$의 nonzero singular values\n",
    "    * {$Av_1,...,Av_r$} : orthogonal basis for $ColA$(A의 컬럼스페이스), rank $A =r$\n",
    "  \n",
    "* Theorem 10. The Singular Value Decomposition(SVD)\n",
    "    * $A$는 $n$ x $n$ matrix이고 rank가 $r$일때(nonzero eigenvalue의 제곱근)\n",
    "    * $m$ x $n$ matrix $\\Sigma$가 존재\n",
    "        * $\\Sigma = \\begin{pmatrix} D & 0\\\\0&0 \\end{pmatrix}$ , $ D = \\begin{pmatrix} \\sigma_1 &&&\\\\&.&.&\\\\ &&&\\sigma_r \\end{pmatrix}$\n",
    "        * $\\Sigma$는 m x n matrix이고 $D$는 r x r matrix\n",
    "    * $m$ x $m$ 인 ortogonal matrix(각 컬럼벡터들이 orthogonal하면서 orthonormal한 matrix)$U$,$n$ x $n$인 orthogonal matrix$V$\n",
    "        * $A =U\\Sigma V^T$\n",
    "        * $U$의 컬럼 : $A$의 left singular vectors\n",
    "        * $V$의 컬럼 : $A$의 right singular vectors\n",
    "\n",
    "* Bases for Fundamental Subspaces\n",
    "    * SVD : $A = U\\Sigma V^T$\n",
    "        * $A : m$ x $n, U: m$ x $m, E: m$ x $n, V: n$ x $n$\n",
    "        * rank $A : r$\n",
    "        * $u_1,...,u_r$ : left singular vectors \n",
    "            * orthonormal basis for $Col A$\n",
    "        * $v_1,...,v_n$ : right singular vectors\n",
    "            * $Av_{r+1}=0,..Av_n=0$ in $Nul A$\n",
    "            * rank $A = r$ , dim $Nul A = n-r$\n",
    "     * Using Ch5.1 Theorem 3\n",
    "        * $(Row A)^\\perp=Nul A$ \n",
    "        * $(Col A)^\\perp=Nul A^T$ \n",
    "     * {$u_{r+1},..,u_m$} : orthonrmal basis for $Nul A^T$\n",
    "     * {$v_{r+1},..,v_n$} : orthonrmal basis for $Nul A$\n",
    "     * {$v_1,...,v_r$} : orthonormal basis for $Row A$\n",
    "\n",
    "* Theroem. The Invertible Matrix Theorem (concluded)\n",
    "    * A가 invertible 한 square matrix\n",
    "        * $u.(ColA)^\\perp=${0}\n",
    "        * $v.(NulA)^\\perp=R^n$\n",
    "        * $w.Row A=R^n$\n",
    "        * $x.A$ has $n$ nonzero singular values\n",
    "\n",
    "* Reduced SVD\n",
    "    * $A = U\\Sigma V^T$에서 $U$를 더 쉽게 찾기 위한 방법 : block matrix\n",
    "        * $U = [u_1,...,u_m] = [U_r | U_{m-r}]$ ,$U_r=[u_1,...u_r]$\n",
    "        * $V= [v_1,v_2.....,v_n]=[V_r | V_{n-r}]$\n",
    "    * $A = [U_r|U_{m-r}]\\begin{pmatrix} D&0\\\\0&0 \\end{pmatrix} \\begin{pmatrix} {V_r}^T \\\\V_{n-r}^T \\end{pmatrix}=U_rDV_r^T$\n",
    "\n",
    "* Pseudoinverse (the Moore-Penrose Inverse)\n",
    "    * reduced SVD :$A = U_rDV_r^T$\n",
    "    * pseudoinverse : $A^+=V_rD^{-1}U_r^T$\n",
    "    * $Ax=b \\to \\hat x=A^+b=V_rD^{-1}U_r^Tb$\n",
    "        * $A\\hat x=U_rU_r^Tb=\\hat b$\n",
    "    * $\\hat x$은 least-squares solution of $Ax=b$\n",
    "    * $\\hat x$는 $Ax=b$의 least-square solution중에 가장 length가 작다\n",
    "\n",
    "* Applications\n",
    "    * least-square solution : 모든 linear equation을 풀때 사용가능\n",
    "    * variance 분석에 사용\n",
    "    * $\\lVert Ax-A^*x \\rVert$ 가 충분히 작을때 Truncated SVD(일부를 잘라내면서 근사SVD)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
