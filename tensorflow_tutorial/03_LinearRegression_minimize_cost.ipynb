{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning의 목표 : cost의 최소화 \n",
    "\n",
    "### Gradient descent algorithm\n",
    "* Minimize cost function\n",
    "* Gradient descent is used many minimization problems\n",
    "* For a given cost function, cost (W,b), it will find W, b to minimize cost\n",
    "* 변수가 많을 때도 사용 가능 ex. cost(W1, W2,....)\n",
    "\n",
    "### 작동원리 \n",
    "1. 한 점에서 시작 \n",
    "2. cost가 줄어들도록 W,b를 아주 조금씩 바꾼다.  \n",
    "3. 해당 점에서 기울기를 계산해서, cost를 최소화 하는 방향으로 업데이트(W = W - learning_rate*기울기)를 해나감\n",
    "    * 기울기 : cost를 W로 미분한 값 \n",
    "    * learning rate : 얼마 만큼 변화를 크게 / 작게 업데이트 할지 \n",
    "    * 기울기가 음수이거나 양수이거나 상관 없이 적용이 가능(음수인 경우에도 빼주면 더해지기 때문에 0에 수렴)\n",
    "4. 최소점에 도달 할때 까지 반복 : 기울기가 더 이상 줄어 들지 않는 점, 0에 가까워 질수록 cost가 최소값을 가짐\n",
    "\n",
    "### 특징\n",
    "* local minimum과 global minimum이 일치하는 경우에만 사용 가능 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000|  74.66667\n",
      "-2.429|  54.85714\n",
      "-1.857|  38.09524\n",
      "-1.286|  24.38095\n",
      "-0.714|  13.71429\n",
      "-0.143|   6.09524\n",
      " 0.429|   1.52381\n",
      " 1.000|   0.00000\n",
      " 1.571|   1.52381\n",
      " 2.143|   6.09524\n",
      " 2.714|  13.71429\n",
      " 3.286|  24.38095\n",
      " 3.857|  38.09524\n",
      " 4.429|  54.85714\n",
      " 5.000|  74.66667\n"
     ]
    }
   ],
   "source": [
    "# cost function을 python으로 구현 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1,2,3])\n",
    "Y = np.array([1,2,3])\n",
    "\n",
    "# cost 계산 함수 : (WX -Y)^2 를 모두 합해서 평균을 낸 값 \n",
    "def cost_func(W, X, Y) : # python으로 계산 할 때는 각 array의 값을 꺼내서 계산해야함 \n",
    "    c = 0\n",
    "    for i in range(len(X)) :\n",
    "        c += (W * X[i] - Y[i]) ** 2\n",
    "    return c / len(X)\n",
    "\n",
    "for feed_W in np.linspace(-3, 5, num=15) :  # linspace : -3~5까지 15개 구간으로 나눈 배열 생성\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    print(\"{:6.3f}|{:10.5f}\".format(feed_W, curr_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.        , -2.42857143, -1.85714286, -1.28571429, -0.71428571,\n",
       "       -0.14285714,  0.42857143,  1.        ,  1.57142857,  2.14285714,\n",
       "        2.71428571,  3.28571429,  3.85714286,  4.42857143,  5.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(-3,5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000|  74.66667\n",
      "-2.429|  54.85714\n",
      "-1.857|  38.09524\n",
      "-1.286|  24.38095\n",
      "-0.714|  13.71429\n",
      "-0.143|   6.09524\n",
      " 0.429|   1.52381\n",
      " 1.000|   0.00000\n",
      " 1.571|   1.52381\n",
      " 2.143|   6.09524\n",
      " 2.714|  13.71429\n",
      " 3.286|  24.38095\n",
      " 3.857|  38.09524\n",
      " 4.429|  54.85714\n",
      " 5.000|  74.66667\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 로 구현 \n",
    "\n",
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])\n",
    "\n",
    "# tensorflow로는 배열간 연산을 한번에 쉽게 할 수 있다. \n",
    "\n",
    "def cost_func(W, X, Y) : \n",
    "    hypothesis = X * W\n",
    "    return tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "W_values = np.linspace(-3,5, num=15)\n",
    "cost_values = []\n",
    "\n",
    "for feed_W in W_values :\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    cost_values.append(curr_cost)\n",
    "    print(\"{:6.3f}|{:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([6.688019], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = tf.Variable(tf.random.normal([1], -100., 100.))\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|18332.2188| 47.398293\n",
      "   10| 3855.3564| 22.638384\n",
      "   20|  810.9046| 11.283927\n",
      "   30|  170.6631|  6.076973\n",
      "   40|   36.0217|  3.689155\n",
      "   50|    7.7069|  2.594144\n",
      "   60|    1.7524|  2.091991\n",
      "   70|    0.5001|  1.861713\n",
      "   80|    0.2368|  1.756112\n",
      "   90|    0.1814|  1.707684\n",
      "  100|    0.1698|  1.685477\n",
      "  110|    0.1673|  1.675292\n",
      "  120|    0.1668|  1.670622\n",
      "  130|    0.1667|  1.668481\n",
      "  140|    0.1667|  1.667498\n",
      "  150|    0.1667|  1.667048\n",
      "  160|    0.1667|  1.666842\n",
      "  170|    0.1667|  1.666747\n",
      "  180|    0.1667|  1.666703\n",
      "  190|    0.1667|  1.666684\n",
      "  200|    0.1667|  1.666674\n",
      "  210|    0.1667|  1.666670\n",
      "  220|    0.1667|  1.666668\n",
      "  230|    0.1667|  1.666667\n",
      "  240|    0.1667|  1.666667\n",
      "  250|    0.1667|  1.666667\n",
      "  260|    0.1667|  1.666667\n",
      "  270|    0.1667|  1.666667\n",
      "  280|    0.1667|  1.666667\n",
      "  290|    0.1667|  1.666667\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent with tensorflow\n",
    "tf.random.set_seed(0)  # random seed 초기화 \n",
    "\n",
    "X = [1., 2., 3., 4.]\n",
    "Y = [1., 3., 5., 7.]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1], -100., 100.)) # 가중치 랜덤하게 초기화 : 어느값을 주어도 동일한 결과를 출력 \n",
    "\n",
    "for step in range(300) :\n",
    "    hypothesis = W * X\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "    alpha = 0.01\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign(descent) # 새로운 값을 W에 할당 \n",
    "\n",
    "    if step % 10 == 0 :\n",
    "        print('{:5}|{:10.4f}|{:10.6f}'.format(step, cost.numpy(), W.numpy()[0])) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
