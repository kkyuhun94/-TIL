{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiVariable Linear Regression\n",
    "* Multi varaiable : Multi feature \n",
    "* $H(x_1,x_2,x_3,....,x_n) = w_1x_1 + w_2x_2 + w_3x_3 +...+w_nx_n + b$\n",
    "    * using matrix : $H(X) = XW$\n",
    "    * TensorFlow : 이론적으로 사용할 때는 $H(x)=Wx+b$로 표현 하지만 텐서플로우에서는 $H(X) = XW$로 사용\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0| 109531.6016\n",
      "   50|   1216.6608\n",
      "  100|     14.7920\n",
      "  150|      1.4555\n",
      "  200|      1.3069\n",
      "  250|      1.3046\n",
      "  300|      1.3040\n",
      "  350|      1.3034\n",
      "  400|      1.3028\n",
      "  450|      1.3022\n",
      "  500|      1.3016\n",
      "  550|      1.3009\n",
      "  600|      1.3003\n",
      "  650|      1.2997\n",
      "  700|      1.2991\n",
      "  750|      1.2985\n",
      "  800|      1.2979\n",
      "  850|      1.2973\n",
      "  900|      1.2967\n",
      "  950|      1.2961\n",
      " 1000|      1.2955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "# data\n",
    "x1 = [73., 93., 89., 96., 73.]\n",
    "x2 = [80., 88., 91., 98., 66.]\n",
    "x3 = [75., 93., 90., 100., 70.]\n",
    "# label\n",
    "Y = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# random weight \n",
    "w1 = tf.Variable(tf.random.normal([1]))\n",
    "w2 = tf.Variable(tf.random.normal([1]))\n",
    "w3 = tf.Variable(tf.random.normal([1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000+1) :\n",
    "    # tf.GradientTape() : costfunction의 기울기등 모든 연산을 테이프에 기록하는 API \n",
    "    with tf.GradientTape() as tape :     \n",
    "        hypothesis = w1*x1 + w2*x2 + w3*x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    \n",
    "    # calculates the gradients of the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b]) # cost를 리스트 원소별로 각각 미분한 것 \n",
    "    \n",
    "    # update w1, w2, w3 and b \n",
    "    w1.assign_sub(learning_rate * w1_grad)  # w1 에 learningrate*미분값 만큼빼서 업데이트 \n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 == 0 :\n",
    "        print(\"{:5}|{:12.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|49057.2891\n",
      "  100|   10.4687\n",
      "  200|    4.4225\n",
      "  300|    4.4142\n",
      "  400|    4.4068\n",
      "  500|    4.3994\n",
      "  600|    4.3920\n",
      "  700|    4.3847\n",
      "  800|    4.3774\n",
      "  900|    4.3701\n",
      " 1000|    4.3628\n",
      " 1100|    4.3556\n",
      " 1200|    4.3484\n",
      " 1300|    4.3413\n",
      " 1400|    4.3341\n",
      " 1500|    4.3270\n",
      " 1600|    4.3199\n",
      " 1700|    4.3129\n",
      " 1800|    4.3058\n",
      " 1900|    4.2989\n",
      " 2000|    4.2919\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "# using Matrix : Multivariable linear regression\n",
    "data = np.array([\n",
    "    #x1 , x2, x3, y\n",
    "    [73. , 80., 75., 152.],\n",
    "    [93., 88., 93., 185.],\n",
    "    [89., 91., 90., 180.],\n",
    "    [96., 98., 100., 196.],\n",
    "    [73., 66., 70., 142.]\n",
    "], dtype = np.float32)\n",
    "\n",
    "# slice data\n",
    "X = data[:, :-1] # x1,x2,x3\n",
    "y = data[:,[-1]] # y \n",
    "\n",
    "W = tf.Variable(tf.random.normal([3,1])) # shape(3,1)로 생성\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# hypothesis, prediction function\n",
    "def predict(X) :\n",
    "    return tf.matmul(X,W) + b \n",
    "\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1) :\n",
    "    with tf.GradientTape() as tape :\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "    \n",
    "    W_grad, b_grad = tape.gradient(cost, [W,b])   \n",
    "    #tape.gradient : 미분을 계산해줌 \n",
    "    \n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 100 == 0 :\n",
    "        print(\"{:5}|{:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal([3,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
       "array([[-0.28642625],\n",
       "       [ 2.1627512 ],\n",
       "       [-0.3980041 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-2.0558567], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73.,  80.,  75.],\n",
       "       [ 93.,  88.,  93.],\n",
       "       [ 89.,  91.,  90.],\n",
       "       [ 96.,  98., 100.],\n",
       "       [ 73.,  66.,  70.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.],\n",
       "       [185.],\n",
       "       [180.],\n",
       "       [196.],\n",
       "       [142.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[205.89403],\n",
       "       [240.30717],\n",
       "       [240.73746],\n",
       "       [257.9994 ],\n",
       "       [185.10709]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
